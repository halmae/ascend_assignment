"""
ASCEND Challenge - ë°ì´í„° íƒìƒ‰ ë° ë¶„ì„
Phase 0: ë°ì´í„° ì´í•´ ë° ê°€ì„¤ ìˆ˜ë¦½ì„ ìœ„í•œ íƒìƒ‰ì  ë¶„ì„
"""

import pandas as pd
import numpy as np
from pathlib import Path
import gzip
import json
from datetime import datetime, timedelta
from collections import Counter

class DataExplorer:
    """4ê°€ì§€ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ íƒìƒ‰í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.streams = {
            'trades': None,
            'orderbook': None,
            'liquidations': None,
            'ticker': None
        }
        
    def load_sample(self, stream_name: str, nrows: int = 10000):
        """ë°ì´í„° ìƒ˜í”Œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ë§Œ)"""
        file_path = self.data_dir / f"{stream_name}.csv.gz"
        
        print(f"\n{'='*60}")
        print(f"ğŸ“‚ Loading {stream_name}.csv.gz...")
        print(f"{'='*60}")
        
        try:
            # ì••ì¶• íŒŒì¼ ì½ê¸°
            df = pd.read_csv(file_path, nrows=nrows)
            self.streams[stream_name] = df
            
            print(f"âœ… Loaded {len(df):,} rows")
            print(f"ğŸ“Š Columns: {list(df.columns)}")
            print(f"ğŸ’¾ Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
            
            return df
        except Exception as e:
            print(f"âŒ Error loading {stream_name}: {e}")
            return None
    
    def analyze_structure(self, stream_name: str):
        """ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        df = self.streams.get(stream_name)
        if df is None:
            print(f"âš ï¸  {stream_name} not loaded")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ” STRUCTURE ANALYSIS: {stream_name.upper()}")
        print(f"{'='*60}\n")
        
        # 1. ê¸°ë³¸ ì •ë³´
        print("ğŸ“‹ Basic Info:")
        print(f"   Rows: {len(df):,}")
        print(f"   Columns: {len(df.columns)}")
        print(f"   Dtypes:\n{df.dtypes}\n")
        
        # 2. ìƒ˜í”Œ ë°ì´í„°
        print("ğŸ“ Sample Data (first 3 rows):")
        print(df.head(3))
        print()
        
        # 3. ê²°ì¸¡ê°’
        null_counts = df.isnull().sum()
        if null_counts.any():
            print("âš ï¸  Null Values:")
            print(null_counts[null_counts > 0])
        else:
            print("âœ… No null values")
        print()
        
        # 4. ê¸°ìˆ  í†µê³„
        print("ğŸ“ˆ Numerical Statistics:")
        print(df.describe())
        print()
        
        return df
    
    def analyze_timestamps(self, stream_name: str, timestamp_col: str = 'timestamp'):
        """íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ì„ - Dirty Dataì˜ í•µì‹¬"""
        df = self.streams.get(stream_name)
        if df is None or timestamp_col not in df.columns:
            print(f"âš ï¸  Cannot analyze timestamps for {stream_name}")
            return
        
        print(f"\n{'='*60}")
        print(f"â° TIMESTAMP ANALYSIS: {stream_name.upper()}")
        print(f"{'='*60}\n")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ë°€ë¦¬ì´ˆ ë˜ëŠ” ë§ˆì´í¬ë¡œì´ˆ)
        ts = df[timestamp_col].values
        
        # 1. ê¸°ë³¸ ì •ë³´
        print("ğŸ“… Time Range:")
        print(f"   First: {ts[0]}")
        print(f"   Last: {ts[-1]}")
        print(f"   Duration: {ts[-1] - ts[0]:,} units")
        print()
        
        # 2. Out-of-order ì²´í¬
        diff = np.diff(ts)
        out_of_order = np.sum(diff < 0)
        out_of_order_pct = (out_of_order / len(diff)) * 100
        
        print("ğŸ”€ Out-of-Order Check:")
        print(f"   Total events: {len(ts):,}")
        print(f"   Out-of-order: {out_of_order:,} ({out_of_order_pct:.3f}%)")
        
        if out_of_order > 0:
            print(f"   âš ï¸  DIRTY DATA DETECTED!")
            # ê°€ì¥ í° ì—­ì „ ì°¾ê¸°
            worst_idx = np.argmin(diff)
            print(f"   Worst case at index {worst_idx}:")
            print(f"      Before: {ts[worst_idx]}")
            print(f"      After: {ts[worst_idx + 1]}")
            print(f"      Diff: {diff[worst_idx]:,}")
        else:
            print(f"   âœ… All timestamps in order")
        print()
        
        # 3. ê°„ê²© ë¶„ì„
        intervals = diff[diff > 0]  # ì–‘ìˆ˜ë§Œ
        print("â±ï¸  Interval Statistics (positive only):")
        print(f"   Mean: {np.mean(intervals):.2f}")
        print(f"   Median: {np.median(intervals):.2f}")
        print(f"   Std: {np.std(intervals):.2f}")
        print(f"   Min: {np.min(intervals):.2f}")
        print(f"   Max: {np.max(intervals):.2f}")
        print()
        
        # 4. ê°„ê²© ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨)
        print("ğŸ“Š Interval Distribution:")
        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
        for p in percentiles:
            val = np.percentile(intervals, p)
            print(f"   {p:2d}th percentile: {val:.2f}")
        print()
        
        # 5. ì¤‘ë³µ íƒ€ì„ìŠ¤íƒ¬í”„
        duplicates = len(ts) - len(np.unique(ts))
        dup_pct = (duplicates / len(ts)) * 100
        print(f"ğŸ” Duplicate Timestamps:")
        print(f"   Count: {duplicates:,} ({dup_pct:.3f}%)")
        if duplicates > 0:
            print(f"   âš ï¸  DUPLICATE EVENTS DETECTED!")
        print()
        
        return {
            'out_of_order': out_of_order,
            'out_of_order_pct': out_of_order_pct,
            'duplicates': duplicates,
            'dup_pct': dup_pct,
            'mean_interval': np.mean(intervals),
            'median_interval': np.median(intervals)
        }
    
    def analyze_liquidations(self):
        """ì²­ì‚° ì´ë²¤íŠ¸ ë¶„ì„ - í”„ë¡œì íŠ¸ì˜ í•µì‹¬"""
        df = self.streams.get('liquidations')
        if df is None:
            print("âš ï¸  Liquidations not loaded")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ’¥ LIQUIDATION ANALYSIS")
        print(f"{'='*60}\n")
        
        # 1. ê¸°ë³¸ í†µê³„
        print("ğŸ“Š Basic Statistics:")
        print(f"   Total liquidations: {len(df):,}")
        
        if 'quantity' in df.columns or 'qty' in df.columns:
            qty_col = 'quantity' if 'quantity' in df.columns else 'qty'
            print(f"   Total quantity: {df[qty_col].sum():,.2f}")
            print(f"   Mean quantity: {df[qty_col].mean():.2f}")
            print(f"   Median quantity: {df[qty_col].median():.2f}")
            print(f"   Max quantity: {df[qty_col].max():.2f}")
        
        if 'side' in df.columns:
            print(f"\n   By Side:")
            print(df['side'].value_counts())
        print()
        
        # 2. ëŒ€ê·œëª¨ ì²­ì‚° íƒì§€
        if 'quantity' in df.columns or 'qty' in df.columns:
            qty_col = 'quantity' if 'quantity' in df.columns else 'qty'
            
            # ìƒìœ„ 1% ë¥¼ "ëŒ€ê·œëª¨"ë¡œ ì •ì˜
            threshold_99 = df[qty_col].quantile(0.99)
            threshold_95 = df[qty_col].quantile(0.95)
            
            massive_liq = df[df[qty_col] >= threshold_99]
            large_liq = df[df[qty_col] >= threshold_95]
            
            print("ğŸ”¥ Large Liquidation Events:")
            print(f"   99th percentile threshold: {threshold_99:.2f}")
            print(f"   Massive liquidations (>99%): {len(massive_liq):,}")
            print(f"   95th percentile threshold: {threshold_95:.2f}")
            print(f"   Large liquidations (>95%): {len(large_liq):,}")
            print()
            
            # ê°€ì¥ í° ì²­ì‚° ì´ë²¤íŠ¸ë“¤
            print("ğŸ’£ Top 5 Largest Liquidations:")
            top5 = df.nlargest(5, qty_col)
            for idx, row in top5.iterrows():
                print(f"   {row[qty_col]:.2f} @ {row.get('price', 'N/A')}")
            print()
        
        # 3. ì‹œê°„ë³„ ë¶„í¬ (íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ìˆë‹¤ë©´)
        if 'timestamp' in df.columns:
            ts_stats = self.analyze_timestamps('liquidations')
            
            # ì²­ì‚°ì´ ì§‘ì¤‘ëœ êµ¬ê°„ ì°¾ê¸°
            timestamps = df['timestamp'].values
            diff = np.diff(timestamps)
            
            # ì§§ì€ ì‹œê°„ì— ë§ì€ ì²­ì‚° = cascade
            print("âš¡ Liquidation Cascade Detection:")
            print("   Looking for rapid succession of liquidations...")
            
            # 1ì´ˆ ë‚´ì— ë°œìƒí•œ ì²­ì‚° ê·¸ë£¹
            one_second = 1000000  # ë§ˆì´í¬ë¡œì´ˆ ê¸°ì¤€
            if diff.max() > one_second:  # ë°€ë¦¬ì´ˆ ê¸°ì¤€ì´ë©´
                one_second = 1000
            
            rapid_events = np.sum(diff < one_second)
            rapid_pct = (rapid_events / len(diff)) * 100
            
            print(f"   Events within 1 second of previous: {rapid_events:,} ({rapid_pct:.2f}%)")
            print()
        
        return df
    
    def analyze_orderbook(self):
        """ì˜¤ë”ë¶ ë¶„ì„ - ìœ ë™ì„± ë° spread"""
        df = self.streams.get('orderbook')
        if df is None:
            print("âš ï¸  Orderbook not loaded")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ“– ORDERBOOK ANALYSIS")
        print(f"{'='*60}\n")
        
        print("ğŸ“Š Columns available:")
        print(df.columns.tolist())
        print()
        
        # Bid/Ask spread ë¶„ì„
        if 'best_bid' in df.columns and 'best_ask' in df.columns:
            df['spread'] = df['best_ask'] - df['best_bid']
            df['spread_pct'] = (df['spread'] / df['best_bid']) * 100
            
            print("ğŸ’° Bid-Ask Spread Analysis:")
            print(f"   Mean spread: {df['spread'].mean():.2f}")
            print(f"   Median spread: {df['spread'].median():.2f}")
            print(f"   Mean spread %: {df['spread_pct'].mean():.4f}%")
            print(f"   Max spread: {df['spread'].max():.2f}")
            print(f"   Max spread %: {df['spread_pct'].max():.4f}%")
            print()
            
            # Crossed market íƒì§€ (bid > ask)
            crossed = df[df['best_bid'] > df['best_ask']]
            if len(crossed) > 0:
                print(f"âš ï¸  CROSSED MARKET DETECTED!")
                print(f"   Count: {len(crossed):,} ({len(crossed)/len(df)*100:.3f}%)")
                print(f"   This is DIRTY DATA!")
                print()
            
            # Wide spread (ë¹„ì •ìƒì ìœ¼ë¡œ í° spread)
            spread_99 = df['spread_pct'].quantile(0.99)
            wide_spread = df[df['spread_pct'] > spread_99]
            print(f"ğŸ“ Wide Spread Events (>99th percentile):")
            print(f"   Threshold: {spread_99:.4f}%")
            print(f"   Count: {len(wide_spread):,}")
            print()
        
        # Depth ë¶„ì„
        depth_cols = [col for col in df.columns if 'qty' in col or 'quantity' in col]
        if depth_cols:
            print(f"ğŸ“š Depth Information:")
            print(f"   Available depth columns: {depth_cols}")
            # ì¶”ê°€ ë¶„ì„...
        
        return df
    
    def analyze_trades(self):
        """ê±°ë˜ ë¶„ì„"""
        df = self.streams.get('trades')
        if df is None:
            print("âš ï¸  Trades not loaded")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ’± TRADE ANALYSIS")
        print(f"{'='*60}\n")
        
        print("ğŸ“Š Basic Statistics:")
        print(f"   Total trades: {len(df):,}")
        
        if 'price' in df.columns:
            print(f"   Price range: {df['price'].min():.2f} - {df['price'].max():.2f}")
            print(f"   Mean price: {df['price'].mean():.2f}")
            
            # Fat-finger ê°€ê²© íƒì§€
            price_mean = df['price'].mean()
            price_std = df['price'].std()
            
            # í‰ê· ì—ì„œ 5 í‘œì¤€í¸ì°¨ ì´ìƒ ë²—ì–´ë‚œ ê°€ê²©
            outliers = df[np.abs(df['price'] - price_mean) > 5 * price_std]
            
            if len(outliers) > 0:
                print(f"\nâš ï¸  FAT-FINGER PRICES DETECTED!")
                print(f"   Count: {len(outliers):,}")
                print(f"   Extreme prices:")
                for idx, row in outliers.head(5).iterrows():
                    print(f"      {row['price']:.2f}")
                print()
        
        if 'quantity' in df.columns or 'qty' in df.columns:
            qty_col = 'quantity' if 'quantity' in df.columns else 'qty'
            print(f"   Total volume: {df[qty_col].sum():,.2f}")
            print(f"   Mean size: {df[qty_col].mean():.4f}")
        
        if 'side' in df.columns:
            print(f"\n   By Side:")
            print(df['side'].value_counts())
        
        return df
    
    def generate_hypothesis(self):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì„¤ ìƒì„± ì œì•ˆ"""
        print(f"\n{'='*60}")
        print(f"ğŸ’¡ HYPOTHESIS SUGGESTIONS")
        print(f"{'='*60}\n")
        
        print("Based on the data analysis, here are potential hypotheses:\n")
        
        # Liquidation ê´€ë ¨
        liq = self.streams.get('liquidations')
        if liq is not None:
            print("1ï¸âƒ£  LIQUIDATION-BASED HYPOTHESIS:")
            print("   H1: After a liquidation event exceeding X quantity,")
            print("       the orderbook becomes unreliable for Y seconds.")
            print()
            print("   H2: When multiple liquidations occur within Z milliseconds,")
            print("       it indicates a cascade and decision should be HALTED.")
            print()
        
        # Orderbook ê´€ë ¨
        ob = self.streams.get('orderbook')
        if ob is not None and 'spread' in ob.columns:
            spread_99 = ob['spread_pct'].quantile(0.99)
            print("2ï¸âƒ£  ORDERBOOK-BASED HYPOTHESIS:")
            print(f"   H3: When bid-ask spread exceeds {spread_99:.4f}%,")
            print("       the market is illiquid and decisions should be RESTRICTED.")
            print()
            print("   H4: Crossed market (bid > ask) indicates data corruption,")
            print("       triggering immediate QUARANTINE.")
            print()
        
        # Timestamp ê´€ë ¨
        print("3ï¸âƒ£  DATA QUALITY HYPOTHESIS:")
        print("   H5: Out-of-order timestamps indicate system overload,")
        print("       degrading Trust State from TRUSTED to DEGRADED.")
        print()
        print("   H6: When event delays exceed P milliseconds,")
        print("       real-time decision-making becomes unreliable.")
        print()
        
        print("4ï¸âƒ£  COMBINED HYPOTHESIS:")
        print("   H7: The combination of:")
        print("       - Large liquidation")
        print("       - Wide spread")
        print("       - Out-of-order data")
        print("       should immediately HALT all decisions until recovery.")
        print()
        
        print("\n" + "="*60)
        print("Next Step: Define specific thresholds (X, Y, Z, P) from data")
        print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                          â•‘
â•‘          ASCEND Challenge - Data Explorer                â•‘
â•‘       Phase 0: Understanding Your Data                   â•‘
â•‘                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•¨)
    data_dir = "data/validation"
    
    print(f"ğŸ“‚ Data directory: {data_dir}")
    print(f"â³ Loading data samples...\n")
    
    explorer = DataExplorer(data_dir)
    
    # 1. ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ë¡œë“œ (ìƒ˜í”Œ)
    for stream in ['trades', 'orderbook', 'liquidations', 'ticker']:
        explorer.load_sample(stream, nrows=50000)  # 5ë§Œ í–‰ì”© ìƒ˜í”Œë§
    
    print("\n" + "="*60)
    print("âœ… All streams loaded! Starting analysis...")
    print("="*60)
    
    # 2. ê° ìŠ¤íŠ¸ë¦¼ ë¶„ì„
    for stream in ['liquidations', 'orderbook', 'trades', 'ticker']:
        if explorer.streams[stream] is not None:
            explorer.analyze_structure(stream)
            explorer.analyze_timestamps(stream)
    
    # 3. íŠ¹í™” ë¶„ì„
    explorer.analyze_liquidations()
    explorer.analyze_orderbook()
    explorer.analyze_trades()
    
    # 4. ê°€ì„¤ ì œì•ˆ
    explorer.generate_hypothesis()
    
    print("\nâœ… Analysis complete!")
    print("ğŸ’¾ Review the output and start forming your hypotheses.")
    
    return explorer


if __name__ == "__main__":
    explorer = main()