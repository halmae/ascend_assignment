"""
Data Source - Historical/Realtime í†µí•© ë°ì´í„° ì†ŒìŠ¤ (ìµœì í™” ë²„ì „)

================================================================================
v2 ìµœì í™”:
- Orderbookì„ row ë‹¨ìœ„ê°€ ì•„ë‹Œ timestamp ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬
- iloc ìŠ¬ë¼ì´ì‹± ëŒ€ì‹  ì¸ë±ìŠ¤ ê¸°ë°˜ ì ‘ê·¼
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
================================================================================
"""
import asyncio
import json
from abc import ABC, abstractmethod
from collections import OrderedDict
from datetime import datetime
from pathlib import Path
from typing import Iterator, Optional, Dict, AsyncIterator, List, Tuple
from dataclasses import dataclass
import heapq

import pandas as pd
import numpy as np

from src.enums import EventType
from src.data_types import Event


@dataclass
class SourceStats:
    """ë°ì´í„° ì†ŒìŠ¤ í†µê³„"""
    events_total: int = 0
    events_processed: int = 0
    duplicates_filtered: int = 0
    out_of_order: int = 0
    reconnects: int = 0


class DataSource(ABC):
    """ë°ì´í„° ì†ŒìŠ¤ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.stats = SourceStats()
        self._is_running = False
    
    @abstractmethod
    def get_events(self) -> Iterator[Event]:
        pass
    
    @abstractmethod
    async def get_events_async(self) -> AsyncIterator[Event]:
        pass
    
    @abstractmethod
    def is_async(self) -> bool:
        pass
    
    def stop(self):
        self._is_running = False


class HistoricalDataSource(DataSource):
    """
    Historical ë°ì´í„° ì†ŒìŠ¤ (ìµœì í™” ë²„ì „)
    
    ìµœì í™”:
    1. Orderbookì„ timestampë³„ë¡œ ë¯¸ë¦¬ ê·¸ë£¹í™”
    2. ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
    3. heapqë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ ë³‘í•© ì •ë ¬
    """
    
    def __init__(self, data_dir: str):
        super().__init__()
        self.data_dir = Path(data_dir)
        self.files = self._find_files()
    
    def is_async(self) -> bool:
        return False
    
    def _find_files(self) -> Dict[str, Path]:
        """ë°ì´í„° íŒŒì¼ ì°¾ê¸°"""
        files = {}
        for name in ['orderbook', 'trades', 'ticker', 'liquidations']:
            for ext in ['.csv', '.csv.gz']:
                path = self.data_dir / f"{name}{ext}"
                if path.exists():
                    files[name] = path
                    break
        return files
    
    def get_events(self) -> Iterator[Event]:
        """
        CSVì—ì„œ ì´ë²¤íŠ¸ ì½ê¸° (ìµœì í™”ëœ ë²„ì „)
        
        ì „ëµ: ê° íŒŒì¼ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , timestamp ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
        """
        self._is_running = True
        
        print(f"ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘...")
        print(f"   Files: {list(self.files.keys())}")
        
        # ê° ìŠ¤íŠ¸ë¦¼ì˜ ì´ë²¤íŠ¸ ì œë„ˆë ˆì´í„°
        generators = {}
        
        if 'orderbook' in self.files:
            generators['orderbook'] = self._stream_orderbook_events()
        if 'trades' in self.files:
            generators['trades'] = self._stream_csv_events('trades', EventType.TRADE)
        if 'ticker' in self.files:
            generators['ticker'] = self._stream_csv_events('ticker', EventType.TICKER)
        if 'liquidations' in self.files:
            generators['liquidations'] = self._stream_csv_events('liquidations', EventType.LIQUIDATION)
        
        # heapqë¥¼ ì‚¬ìš©í•œ ë³‘í•© ì •ë ¬
        # (timestamp, stream_name, event)
        heap = []
        
        # ê° ìŠ¤íŠ¸ë¦¼ì—ì„œ ì²« ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        for name, gen in generators.items():
            try:
                event = next(gen)
                heapq.heappush(heap, (event.local_timestamp, name, event, gen))
            except StopIteration:
                pass
        
        print(f"   âœ… ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” ì™„ë£Œ. ë³‘í•© ì‹œì‘...")
        
        # ë³‘í•© ì •ë ¬ë¡œ ì´ë²¤íŠ¸ ìˆœì„œëŒ€ë¡œ ë°˜í™˜
        while heap and self._is_running:
            ts, name, event, gen = heapq.heappop(heap)
            
            self.stats.events_total += 1
            self.stats.events_processed += 1
            
            yield event
            
            # í•´ë‹¹ ìŠ¤íŠ¸ë¦¼ì—ì„œ ë‹¤ìŒ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            try:
                next_event = next(gen)
                heapq.heappush(heap, (next_event.local_timestamp, name, next_event, gen))
            except StopIteration:
                pass
    
    def _stream_orderbook_events(self) -> Iterator[Event]:
        """
        Orderbook CSV ìŠ¤íŠ¸ë¦¬ë° (timestampë³„ ê·¸ë£¹í™”)
        
        CSV í˜•ì‹: ê° rowê°€ í•˜ë‚˜ì˜ price level
        â†’ ê°™ì€ timestampì˜ rowë“¤ì„ ëª¨ì•„ì„œ í•˜ë‚˜ì˜ ì´ë²¤íŠ¸ë¡œ
        """
        path = self.files['orderbook']
        chunk_size = 500_000  # 50ë§Œ rowsì”©
        
        pending_ts = None
        pending_local_ts = None
        pending_is_snapshot = False
        pending_bids = []
        pending_asks = []
        
        for chunk in pd.read_csv(path, chunksize=chunk_size):
            # timestampë¡œ ì •ë ¬
            chunk = chunk.sort_values('local_timestamp')
            
            for _, row in chunk.iterrows():
                ts = int(row.get('timestamp', 0))
                local_ts = int(row.get('local_timestamp', ts))
                is_snapshot = row.get('is_snapshot', False)
                if isinstance(is_snapshot, str):
                    is_snapshot = is_snapshot.lower() == 'true'
                
                side = str(row.get('side', '')).lower()
                price = float(row.get('price', 0))
                amount = float(row.get('amount', 0))
                
                # ìƒˆë¡œìš´ timestampë©´ ì´ì „ ê²ƒì„ yield
                if pending_ts is not None and pending_ts != ts:
                    if pending_bids or pending_asks:
                        event_type = EventType.SNAPSHOT if pending_is_snapshot else EventType.ORDERBOOK
                        yield Event(
                            event_type=event_type,
                            timestamp=pending_ts,
                            local_timestamp=pending_local_ts,
                            data={'bids': pending_bids, 'asks': pending_asks}
                        )
                    
                    pending_bids = []
                    pending_asks = []
                
                # í˜„ì¬ row ì¶”ê°€
                pending_ts = ts
                pending_local_ts = local_ts
                pending_is_snapshot = is_snapshot
                
                if side == 'bid':
                    pending_bids.append([price, amount])
                elif side == 'ask':
                    pending_asks.append([price, amount])
        
        # ë§ˆì§€ë§‰ pending flush
        if pending_ts is not None and (pending_bids or pending_asks):
            event_type = EventType.SNAPSHOT if pending_is_snapshot else EventType.ORDERBOOK
            yield Event(
                event_type=event_type,
                timestamp=pending_ts,
                local_timestamp=pending_local_ts,
                data={'bids': pending_bids, 'asks': pending_asks}
            )
    
    def _stream_csv_events(self, name: str, event_type: EventType) -> Iterator[Event]:
        """ì¼ë°˜ CSV ìŠ¤íŠ¸ë¦¬ë° (trades, ticker, liquidations)"""
        path = self.files[name]
        
        chunk_sizes = {
            'trades': 100_000,
            'ticker': 50_000,
            'liquidations': 10_000,
        }
        chunk_size = chunk_sizes.get(name, 50_000)
        
        for chunk in pd.read_csv(path, chunksize=chunk_size):
            chunk = chunk.sort_values('local_timestamp')
            
            for _, row in chunk.iterrows():
                ts = int(row.get('timestamp', 0))
                local_ts = int(row.get('local_timestamp', ts))
                
                data = self._extract_data(name, row)
                
                yield Event(
                    event_type=event_type,
                    timestamp=ts,
                    local_timestamp=local_ts,
                    data=data
                )
    
    def _extract_data(self, name: str, row: pd.Series) -> Dict:
        """ì´ë²¤íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        if name == 'trades':
            return {
                'price': float(row.get('price', 0)),
                'quantity': float(row.get('amount', 0)),
                'side': row.get('side', 'unknown'),
            }
        elif name == 'ticker':
            return {
                'last_price': float(row.get('last_price', 0)),
                'funding_rate': row.get('funding_rate'),
            }
        elif name == 'liquidations':
            return {
                'side': row.get('side', 'unknown'),
                'quantity': float(row.get('amount', 0)),
                'price': float(row.get('price', 0)),
            }
        return {}
    
    async def get_events_async(self) -> AsyncIterator[Event]:
        """Historicalì€ ë™ê¸°ì§€ë§Œ async ì¸í„°í˜ì´ìŠ¤ë„ ì œê³µ"""
        for event in self.get_events():
            yield event


class RealtimeDataSource(DataSource):
    """
    Realtime ë°ì´í„° ì†ŒìŠ¤ (WebSocket)
    """
    
    def __init__(self, symbol: str = "btcusdt", duration_sec: int = 60):
        super().__init__()
        self.symbol = symbol
        self.duration_sec = duration_sec
        self.websocket_url = "wss://fstream.binance.com"
        
        # Robustness
        self.seen_trade_ids: OrderedDict = OrderedDict()
        self.seen_depth_ids: OrderedDict = OrderedDict()
        self.max_seen_ids = 10000
        self.last_timestamps: Dict[str, int] = {}
        
        self.start_time: Optional[datetime] = None
    
    def is_async(self) -> bool:
        return True
    
    def get_stream_uri(self) -> str:
        streams = [
            f"{self.symbol}@trade",
            f"{self.symbol}@depth@100ms",
            f"{self.symbol}@forceOrder",
            f"{self.symbol}@ticker",
        ]
        return f"{self.websocket_url}/stream?streams={'/'.join(streams)}"
    
    def get_events(self) -> Iterator[Event]:
        raise NotImplementedError("Realtime source requires async")
    
    async def get_events_async(self) -> AsyncIterator[Event]:
        """WebSocketì—ì„œ ì´ë²¤íŠ¸ ì½ê¸°"""
        import websockets
        
        self._is_running = True
        self.start_time = datetime.now()
        uri = self.get_stream_uri()
        
        while self._is_running:
            elapsed = (datetime.now() - self.start_time).total_seconds()
            if elapsed >= self.duration_sec:
                break
            
            try:
                async with websockets.connect(
                    uri,
                    ping_interval=20,
                    ping_timeout=10,
                ) as ws:
                    if self.stats.reconnects > 0:
                        print(f"\n  ğŸ”„ ì¬ì—°ê²° ì„±ê³µ (#{self.stats.reconnects})")
                    else:
                        print("âœ… WebSocket ì—°ê²° ì„±ê³µ!")
                        print("ğŸ“¡ ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...\n")
                    
                    while self._is_running:
                        elapsed = (datetime.now() - self.start_time).total_seconds()
                        if elapsed >= self.duration_sec:
                            break
                        
                        try:
                            message = await asyncio.wait_for(ws.recv(), timeout=1.0)
                            event = self._parse_message(message)
                            if event:
                                yield event
                        except asyncio.TimeoutError:
                            continue
            
            except Exception as e:
                self.stats.reconnects += 1
                print(f"\n  âš ï¸ ì—°ê²° ëŠê¹€: {e}. 3ì´ˆ í›„ ì¬ì—°ê²°...")
                await asyncio.sleep(3)
                continue
    
    def _parse_message(self, message: str) -> Optional[Event]:
        """WebSocket ë©”ì‹œì§€ íŒŒì‹±"""
        self.stats.events_total += 1
        
        try:
            data = json.loads(message)
        except json.JSONDecodeError:
            return None
        
        payload = data.get('data', {})
        event_type_str = payload.get('e', 'unknown')
        
        local_ts = int(datetime.now().timestamp() * 1000000)
        
        type_map = {
            'trade': EventType.TRADE,
            'depthUpdate': EventType.ORDERBOOK,
            'forceOrder': EventType.LIQUIDATION,
            '24hrTicker': EventType.TICKER,
        }
        
        event_type = type_map.get(event_type_str)
        if event_type is None:
            return None
        
        # ì¤‘ë³µ ì²´í¬
        if event_type == EventType.TRADE:
            trade_id = payload.get('t')
            if trade_id and self._is_duplicate('trade', trade_id):
                self.stats.duplicates_filtered += 1
                return None
        elif event_type == EventType.ORDERBOOK:
            depth_id = f"{payload.get('U', 0)}-{payload.get('u', 0)}"
            if self._is_duplicate('depth', depth_id):
                self.stats.duplicates_filtered += 1
                return None
        
        event_ts = payload.get('E', 0) * 1000
        self._check_out_of_order(event_type_str, event_ts)
        
        event_data = self._extract_data(event_type_str, payload)
        
        self.stats.events_processed += 1
        
        return Event(
            event_type=event_type,
            timestamp=event_ts,
            local_timestamp=local_ts,
            data=event_data
        )
    
    def _extract_data(self, event_type: str, payload: Dict) -> Dict:
        if event_type == 'trade':
            return {
                'price': float(payload.get('p', 0)),
                'quantity': float(payload.get('q', 0)),
                'side': 'sell' if payload.get('m', False) else 'buy',
            }
        elif event_type == 'depthUpdate':
            return {
                'bids': [[float(b[0]), float(b[1])] for b in payload.get('b', [])],
                'asks': [[float(a[0]), float(a[1])] for a in payload.get('a', [])],
            }
        elif event_type == 'forceOrder':
            order = payload.get('o', {})
            return {
                'side': order.get('S', 'unknown'),
                'quantity': float(order.get('q', 0)),
                'price': float(order.get('p', 0)),
            }
        elif event_type == '24hrTicker':
            return {
                'last_price': float(payload.get('c', 0)),
                'funding_rate': float(payload.get('r', 0)) if 'r' in payload else None,
            }
        return {}
    
    def _is_duplicate(self, stream_type: str, msg_id) -> bool:
        seen = self.seen_trade_ids if stream_type == 'trade' else self.seen_depth_ids
        
        if msg_id in seen:
            return True
        
        seen[msg_id] = True
        while len(seen) > self.max_seen_ids:
            seen.popitem(last=False)
        
        return False
    
    def _check_out_of_order(self, stream_type: str, timestamp: int):
        last_ts = self.last_timestamps.get(stream_type, 0)
        if timestamp < last_ts:
            self.stats.out_of_order += 1
        self.last_timestamps[stream_type] = timestamp


def create_data_source(mode: str, **kwargs) -> DataSource:
    """ë°ì´í„° ì†ŒìŠ¤ íŒ©í† ë¦¬"""
    if mode == 'historical':
        return HistoricalDataSource(
            data_dir=kwargs.get('data_dir', './data')
        )
    elif mode == 'realtime':
        return RealtimeDataSource(
            symbol=kwargs.get('symbol', 'btcusdt'),
            duration_sec=kwargs.get('duration_sec', 60)
        )
    else:
        raise ValueError(f"Unknown mode: {mode}")